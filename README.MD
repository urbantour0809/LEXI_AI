<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?logo=python" />
  <img src="https://img.shields.io/badge/FastAPI-ğŸ’¨-brightgreen?logo=fastapi" />
  <img src="https://img.shields.io/badge/EXAONE-3.5-informational?logo=deeplearning" />
  <img src="https://img.shields.io/badge/ChromaDB-Search-orange" />
</p>

# âš–ï¸ LEXI Backend â€“ ë²•ë¥  ì§ˆë¬¸ & ê³„ì•½ì„œ ìƒì„±ê¸° (EXAONE ê¸°ë°˜)

> í•œêµ­ì–´ ë²•ë¥  ì§ˆë¬¸ ì‘ë‹µë¶€í„° ìë™ ê³„ì•½ì„œ ìƒì„±ê¹Œì§€, EXAONE 3.5 ê¸°ë°˜ FastAPI ë°±ì—”ë“œ

---

## ğŸŒŸ ì™œ EXAONE 3.5?

- âœ… **í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸**: í•œêµ­ì–´ ë²•ë¥ /íŒë¡€ì— ìµœì í™”ëœ EXAONE 3.5 ì‚¬ìš©
- âœ… **ìì—°ì–´ ì´í•´ë ¥ ìš°ìˆ˜**: ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°ë„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬
- âœ… **LLM + RAG ì¡°í•©**: íŒë¡€ ë° ì„ë² ë”© ê²€ìƒ‰ ê¸°ë°˜ì˜ ì •í™•í•œ ì‘ë‹µ

---

## âš™ï¸ ì–‘ìí™” ì„¤ì • ì½”ë“œ (answer.py & doc_create.py)

```python
# âœ… 4ë¹„íŠ¸ ì–‘ìí™” ì„¤ì •
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,                # 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©
    bnb_4bit_compute_dtype=torch.float16,  # ì—°ì‚° ì‹œ float16 ì‚¬ìš©
    bnb_4bit_quant_type="nf4",       # NF4 ì–‘ìí™” íƒ€ì… ì‚¬ìš©
    bnb_4bit_use_double_quant=True   # ì´ì¤‘ ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ ì¶”ê°€ ì ˆì•½
)
```

> ğŸš€ VRAM 8GBì—ì„œë„ EXAONE êµ¬ë™ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •ëœ ì´ˆê²½ëŸ‰ ì–‘ìí™” ë°©ì‹ì…ë‹ˆë‹¤.

---

## ğŸ§  ì£¼ìš” AI ë¡œì§ ì½”ë“œ ì˜ˆì‹œ

### ğŸ” ChromaDB íŒë¡€ ê²€ìƒ‰
```python
results = collection.query(query_texts=[query], n_results=3)
return results["documents"]
```

### ğŸ¤– EXAONE ëª¨ë¸ ì‘ë‹µ ìƒì„±
```python
inputs = tokenizer(prompt, return_tensors="pt").to(device)
outputs = model.generate(**inputs, max_new_tokens=512)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
```

### ğŸ“„ ê³„ì•½ì„œ â†’ PDF ë³€í™˜
```python
pdfkit.from_string(html_html, pdf_path, configuration=pdfkit.configuration(wkhtmltopdf="/usr/bin/wkhtmltopdf"))
```

---

## ğŸ–¥ï¸ Windows í™˜ê²½ì—ì„œ GPU ì‚¬ìš© ê°€ì´ë“œ

1. **Windowsì—ì„œ WSL(ë¦¬ëˆ…ìŠ¤ í™˜ê²½) ì„¤ì¹˜**
2. **Anaconda ë˜ëŠ” Minicondaë¡œ ê°€ìƒí™˜ê²½ ìƒì„±**
3. **CUDA ë²„ì „ í™•ì¸**
   ```bash
   nvidia-smi
   ```
4. **CUDA í˜¸í™˜ PyTorch ì„¤ì¹˜**
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
   ```

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ğŸ“¦ backend/
â”œâ”€â”€ generate/
â”‚   â”œâ”€â”€ server.py          # FastAPI ì„œë²„
â”‚   â”œâ”€â”€ answer.py          # EXAONE ê¸°ë°˜ ì‘ë‹µ ìƒì„±
â”‚   â”œâ”€â”€ search.py          # íŒë¡€ ê²€ìƒ‰ (ChromaDB)
â”‚   â”œâ”€â”€ doc_create.py      # ê³„ì•½ì„œ í…ìŠ¤íŠ¸ â†’ PDF
â”œâ”€â”€ document/              # ìƒì„±ëœ ë¬¸ì„œ ì €ì¥
â”œâ”€â”€ static/                # favicon ë“± ì •ì  íŒŒì¼
â”œâ”€â”€ main.py                # Cloudtype í”„ë¡ì‹œ ì„œë²„
â”œâ”€â”€ .env                   # LOCAL_GPU_SERVER ì„¤ì •
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 3. ë¡œì»¬ ì„œë²„ ì‹¤í–‰
cd generate
python server.py
```

> ì™¸ë¶€ ì—°ê²° ì‹œ:
```bash
ngrok http 8001
```

---

## ğŸ” ê¸°íƒ€ ë³´ì•ˆ ë° ìš´ì˜ íŒ

- `.env` íŒŒì¼ì€ ì ˆëŒ€ ì™¸ë¶€ì— ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”!
- ëª¨ë¸ ìºì‹œê°€ ëˆ„ì ë˜ëŠ” ê²½ìš° `~/.cache/huggingface/` ê²½ë¡œ ì •ë¦¬ í•„ìš”
- PDFKitì€ ì„œë²„ ë°°í¬ ì‹œ `wkhtmltopdf` ê²½ë¡œ ì„¤ì • í•„ìˆ˜ (`/usr/bin/wkhtmltopdf`)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ìš© API ì˜ˆì‹œ (Postman)

```json
POST /generate-document
{
  "contract_type": "ê·¼ë¡œê³„ì•½ì„œ",
  "party_a": "í™ê¸¸ë™",
  "party_b": "ì„êº½ì •",
  "contract_date": "2025-02-20",
  "additional_info": "ê³„ì•½ ê¸°ê°„ì€ 2ë…„ì´ë©°, ì›”ê¸‰ì€ 300ë§Œì›ì…ë‹ˆë‹¤."
}
```

---

## ğŸ™Œ í¬ë ˆë”§

- [EXAONE 3.5](https://huggingface.co/LGAI-EXAONE)
- [FastAPI](https://fastapi.tiangolo.com/)
- [ChromaDB](https://www.trychroma.com/)
- [Cloudtype](https://cloudtype.io/)
- ngrok

---

<p align="center">
  <b>Lawyer.ai Backend: ë¹ ë¥´ê³  ì •í™•í•œ í•œêµ­ì–´ ë²•ë¥  ì„œë¹„ìŠ¤</b><br/>
  <em>ë¬¸ì˜ ë° í”¼ë“œë°±ì€ ì–¸ì œë“ ì§€ í™˜ì˜ì…ë‹ˆë‹¤!</em>
</p>
